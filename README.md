
## K-Nearest Neighbor (KNN) (k vizinhos mais pr√≥ximos)
Seu objetivo √© ap√≥s termos os dados classificados(Dados de treino) quando inserimos o dado que queremos saber a qual grupo ele pertence temos que mandar o dado e o k (k significa o n√∫mero de  vizinhos que o novo dado est√° mais pr√≥ximo) ele vai calcular a dist√¢ncia do novo ponto inserido para todos os outros pontos e vai guardar este c√°lculo ap√≥s isso ele vai pegar as k menores distancia e vai colocar o dado na classe predominante.Quanto menor o k estamos mais sujeitos a ru√≠dos mas perdemos um pouco da precis√£o para encontrar um k bom devemos fazer varios teste para ver se o modelo est√° se comportando melhor ou se o algoritmo est√° se saindo mal com o k maior.
Para o algoritmo do knn funcionar perfeitamente precisamos normalizar os dados.

Ex:Se  tiver k=3 e as classes da cor vermelha e azul ele ele vai calcular a dist√¢ncia do novo ponto para todos os dados das classes e logo ap√≥s este c√°lculo ele vai verificar quais s√£o os 3 dados com a menor dist√¢ncia dele e vai verificar qual tem maior predomin√¢ncia se deste 3 dados forem 2 do vermelho ent√£o o novo ponto vai ir para a classe vermelha.

C√≥digo exemplo usando KNN:


![KNN](https://github.com/danielcasanova12/Machine-Leaning-Techiniques/assets/119464431/f2f892f7-16ac-452c-b490-d9e7e542ed91)
Nossa acur√°cia foi maior que 0.9 isso quer dizer que nosso modelo treinado com o algoritmo knn est√° gerando previs√µes corretas para 96,49% dos exemplos no conjunto de testes

## Principal Component Analysis (PCA) An√°lise do Componente Principal
Esta t√©cnica √© uma das mais comuns de redu√ß√£o de dimensionalidade, ou seja ela nos ajuda diminuir as dimens√µes do nosso problema, se tivermos 30 vari√°veis temos 30 dimens√µes ela reduz a quantidade de vari√°veis tentando preservar a variancia dos dados, resumidamente ela cria um novo sistema de vari√°veis que ser√£o uma combina√ß√£o linear dos eixos, elas conseguem explicar melhor os dados do que as vari√°veis iniciais 
![Pca](https://github.com/danielcasanova12/Predicao/assets/119464431/d7905325-dfee-4770-971d-fd777c7c6c0b)

Variancia por que cada nova vari√°vel tem  [0.84136038 0.11751808 0.03473561]

Aqui podemos perceber que o nivel de variancia da primeira vari√°vel √© de 84% e a segunda de 11%
isso quer dizer que com apenas 2 vari√°veis

## ETL (Extract, Transform, Load)
Normalmente √© usado quando n√£o temos capacidade computacional na fonte ou no destino.Ent√£o entre a extra√ß√£o e o load usamos uma engine ou outro servidor para transformar os dados.

## ELT (Extract, Load, Transform)
Ao contr√°rio do ETL ele transforma os dados no final do processo fazendo-se n√£o necess√°rio o uso de engines no meio do caminho.


## Q-learning (Aprendizado por refor√ßo)

O aprendizado por refor√ßo √© o aprendizado cujo nosso agente(intelig√™ncia artificial) vai aprender com as intera√ß√µes com nosso ambiente ele far√° a√ß√µes e receber√° de volta o estado e uma recompensa que pode ser negativa ou positiva, ele aprende com seus erros e acertos. Este tipo de aprendizado de m√°quina √© muito usado na rob√≥tica e tamb√©m em jogos. Uma forma pr√°tica de visualizarmos isso no mundo real podemos ver como ensinamos os cachorros, normalmente come√ßamos ensinando eles pelo b√°sico que seria o deitar sentar e pular e depois que ele j√° aprendeu isso come√ßamos com outras tarefas como buscar uma bolinha que jogamos para ele, conforme ele vai fazendo as tarefas vamos dando recompensas para ele.

## Confusion Matrix
A Confusion Matrix serve para avaliarmos nosso modelos de Classifica√ß√£o, ela √© uma matriz quadrada com as dimens√µes da quantidade de vari√°veis ex: se tivermos 4 vari√°veis ela ser√° uma matriz 4x4. Nas colunas 
![confusionMatriz](https://github.com/danielcasanova12/Predicao/assets/119464431/f2bb54cd-494f-44c7-97a5-b72d3772595d)
Nesta matriz podemos ver na diagonal em vermelho os acertos e na outra diagonal os erros.
Uma das m√©tricas de avalia√ß√£o √© a acur√°cia que se mede com esta f√≥rmula
 ((TP + TN)/N) = 150/165=0.91 = 91%
Temos que cuidar ao usar acur√°cia pois podemos ter dados desbalanceados com dados que s√≥ acontecem em 2% dos casos, se nosso modelo ignorar estes dados nosso modelo vai ter uma acur√°cia de 98% que seria uma acur√°cia boa mas n√£o √© pois ela ignora os casos que queremos analizar 
## Recall(Sensibilidade)
![Screenshot_92](https://github.com/danielcasanova12/Predicao/assets/119464431/2926e306-1e75-4efd-a82e-7cea78ed1ecf)
## Especificidade
√â o inverso do recall ele usa a coluna TN e FP sua f√≥rmula √© :
![Screenshot_93](https://github.com/danielcasanova12/Predicao/assets/119464431/892e4cde-4975-4930-8617-d2a077acde60)

## Precis√£o
Dos classificados como TP e FP quantos % realmente s√£o verdadeiros :
![Screenshot_95](https://github.com/danielcasanova12/Predicao/assets/119464431/59d11973-926e-4002-8a58-8224c530c1d9)
## F1 Score
√â uma m√©dia harm√¥nica que leva em conta a precis√£o e o recall 
![Screenshot_96](https://github.com/danielcasanova12/Predicao/assets/119464431/47796257-2b3f-4074-8fda-0d717aa5683e)
## ROC
A curva ROC √© uma curva que varia de 0.5 a 1 onde 1 significa 100% de  sensibilidade e 100% de especificidade e quando d√° 0.5 o teste n√£o tem capacidade diagn√≥stica nem uma.Idealmente, queremos que nosso modelo tenha uma alta taxa de verdadeiros positivos e uma baixa taxa de falsos positivos, o que significa que a curva ROC estaria mais pr√≥xima do canto superior esquerdo do gr√°fico.

## AUC
A curva AUC facilita para comparar uma curva ROC com outra.Embora os gr√°ficos ROC sejam desenhados usando Taxas de Verdadeiros Positivos e Taxas de Falsos Positivos para resumir matrizes de confus√£o, existem outras m√©tricas que tentam fazer a mesma coisa. Essas m√©tricas s√£o usadas para avaliar o desempenho de modelos de classifica√ß√£o e identificar o equil√≠brio entre a taxa de acertos e a taxa de falsos positivos.

## Dealing With Real-World Data
Bias e Vari√¢ncia: 
 * Bias ou vi√©s √© a dist√¢ncia m√©dia entre as previs√µes e os valores reais.
 * Vari√¢ncia: Dispers√£o das previs√µes.

![Screenshot_97](https://github.com/danielcasanova12/Predicao/assets/119464431/b0897a99-6031-4354-bb1e-8d62b896879f)

O erro √© calculado da seguinte maneira
ùê∏ùëüùëüùëúùëü = ùêµùëñùëéùë†¬≤ + ùëâùëéùëüùëñùëéùëõùëêùëí
Nosso objetivo √© ter um modelo que tenha Bias e variancia baixos para obter o menor erro poss√≠vel.

## Cleaning  Data (Limpeza de Dados)

Este processo nos ajuda a identificar e remover os dados que podem prejudicar o treinamento do nosso modelo 
* Outliers: S√£o valores muito diferentes da maioria dos outros dados.
* Missing Data: Valores ausentes causados por erros da entrada ou perda de dados.
* Erroneous Data: Dados que foram alterados acidentalmente.
* Irrelevant Data: Dados que s√£o irrelevantes para nosso modelo.
* Inconsistent Data: Dados de diferentes fontes ou que foram alterados ao longo do tempo
* Formatting: Dados mal formatados, como diferentes unidades de medidas ou datas.

Esta parte de limpeza de dados √© um passo que pode definir se nosso modelo vai ser um bom modelo ou se nosso modelo ter√° problemas. Devemos dar muita aten√ß√£o nesta parte para garantir que nossos dados realmente estejam limpos e prontos para uso.

## Detec√ß√£o de Outliers
* Z-Score: Essa t√©cnica utiliza a m√©dia e o desvio padr√£o dos dados para identificar outliers. Valores com Z-Score maior que 3 ou menor que -3 geralmente s√£o considerados outliers.
Percentis: Essa t√©cnica divide os dados em quartis. O primeiro quartil (Q1) representa 25% dos dados, o terceiro quartil (Q3) representa 75% dos dados e o intervalo interquartil (IQR) √© a diferen√ßa entre Q3 e Q1. Valores que est√£o fora do intervalo IQR +/- 1.5*IQR podem ser considerados outliers.
Dados Desbalanceados

* Em problemas de classifica√ß√£o, √© comum ter classes desbalanceadas, ou seja, uma classe possui muito mais exemplos que a outra. Isso pode prejudicar o desempenho do modelo, pois ele tende a aprender apenas a classe majorit√°ria.

## T√©cnicas para lidar com dados desbalanceados
* Oversampling: Aumentar artificialmente a quantidade de exemplos na classe minorit√°ria.
* Undersampling: Reduzir artificialmente a quantidade de exemplos na classe majorit√°ria.
* SMOTE (Synthetic Minority Over-sampling Technique): Criar novos exemplos na classe minorit√°ria a partir de exemplos existentes.

## Outras t√©cnicas de pr√©-processamento s√£o elas:
* Binning: Transformar dados num√©ricos em dados categ√≥ricos.
* Transforming: Transformar os dados para melhorar a performance do modelo.
* Encoding: Transformar os dados em um formato compat√≠vel com o modelo.
* Scaling/Normaliza√ß√£o: Ajustar a escala dos dados para que estejam em uma faixa similar.
* Shuffling: Embaralhar os dados para evitar que o modelo aprenda padr√µes indesejados.

* 


